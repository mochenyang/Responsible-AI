# Responsible AI for Data Scientists

> With great power comes great responsibility.

This is not just a quote from the Spider-Man movies, it is also the title of a high-stake [U.S. Congressional Hearing](https://www.govinfo.gov/content/pkg/CHRG-115hhrg30877/html/CHRG-115hhrg30877.htm) that took place on June 26, 2018, with expert witnesses including Greg Brockman (Co-Founder and CTO at OpenAI) and Fei-Fei Li (Stanford Professor and creator of ImageNet). The hearing was convened to discuss the "implications for our society in a future where AI is 
ubiquitous."

In many ways, that "future" is already here. AI is THE buzzword of our time and is influencing an increasing number of individuals and businesses. In fact, AI (and Generative AI in particular) has been shown to possess the characteristics of a [General Purpose Technology](https://www.science.org/doi/10.1126/science.adj0998) {cite:p}`eloundou2024gpts`, meaning that its impact on society will be highly pervasive.

Despite such pervasiveness, it is clear that the impact of AI is not all good and positive. While the benefits of AI are clear, so are the risks and challenges. Take a cursory look at the growing [AI Incident Database](https://incidentdatabase.ai/) and you will see its multitude of atrocities. 

Ensuring responsible applications of AI is as important, if not more so, as pushing the technology forward. This is the reason for us to write a book on "Responsible AI for Data Scientists". 

## Scope of This Book

This book covers fundamental concepts in algorithmic fairness, interpretable machine learning, as well as data privacy, all of which are important topics in Responsible AI.

### Intended Audience

This book is used as lecture materials for MSBA 6341: Responsible AI and MABA xxxx: Responsible AI. As such, its primary intended audience is master-level students in a business analytics program. That being said, it can also be used as a general reference for anyone interested in the topic.

### What This Book Is Not

Two objectives are of primary importance to us in the writing of this book:
1. We offer a human-centric conceptual framework of Responsible AI, which can guide readers to think about Responsible AI issues in a holistic and critical manner. 
2. We also discuss practical techniques / methods to address the aforementioned Responsible AI issues.

We prioritize a balance between these two objectives throughout the book. This choice also implies that
- This book is not a comprehensive treatment of the philosophical / legal / sociological roots of any of the Responsible AI issues.
- This book is not a most up-to-date collection of techniques / algorithms in the Responsible AI community.

## How to Use this Book

This book is compiled using [Jupyter Book](https://jupyterbook.org/en/stable/intro.html) and its source is available on [GitHub](https://github.com/mochenyang/Responsible-AI). 
- To read the book in a static format: simply visit [https://mochenyang.github.io/Responsible-AI](https://mochenyang.github.io/Responsible-AI);
- To edit the book and adapt it for your own purposes, please fork the [repo](https://github.com/mochenyang/Responsible-AI).