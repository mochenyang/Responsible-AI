{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mitigating Algorithmic Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter demonstrates a few representative algorithms for mitigating algorithmic bias. As discussed in the Chapter {doc}`1-1-intro.ipynb`, algorithmic bias can arise from (i) pre-existing bias in data, (ii) bias introduced during model training, and (iii) bias introduced when making predictions / decisions. Accordingly, to mitigate these biases, there are at least three types of approaches:\n",
    "\n",
    "- **Pre-processing Approaches**: pre-process training data to remove existing bias, before training models;\n",
    "- **In-processing Approaches**: modify how models are trained to impose fairness as a learning objective or constraint;\n",
    "- **Post-processing Approaches**: post-process model outputs (e.g., predictions or predicted probabilities) to satisfy certain fairness objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again use the [Compas Recidivism Dataset](https://www.propublica.org/datastore/dataset/compas-recidivism-risk-score-data-and-analysis) for demonstration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Data: Compas Recidivism Dataset\n",
    ":class: note\n",
    "- Location: \"data/compas-scores-two-years.csv\"\n",
    "- Shape: (7214, 53)\n",
    "- Source: ProPublica\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from Chapter {doc}`1-2-measure.ipynb`, we will not use the predicted risk scores from COMPAS (including the ```decile_score``` and ```score_text``` columns). Instead, we will only rely on the ```two_year_recid``` column as ground-truths and build classifiers ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5278, 53)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and clean data\n",
    "import pandas as pd\n",
    "compas = pd.read_csv('../data/compas-scores-two-years.csv')\n",
    "compas = compas[(compas['days_b_screening_arrest'] <= 30) & \n",
    "                (compas['days_b_screening_arrest'] >= -30) &  \n",
    "                (compas['is_recid'] != -1) &\n",
    "                (compas['c_charge_degree'] != 'O') & \n",
    "                (compas['score_text'] != 'N/A')]\n",
    "# again focus only on African-American vs. Caucasian as the protected group of interest\n",
    "compas = compas[compas['race'].isin(['African-American', 'Caucasian'])]\n",
    "compas.reset_index(drop = True, inplace = True)\n",
    "compas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['priors_count', 'age_cat_Greater than 45', 'age_cat_Less than 25',\n",
       "       'c_charge_degree_M', 'race_Caucasian', 'sex_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use two_year_recid as the label, and sex, age_cat, priors_count, c_charge_degree (F for felony, M for misdemeanor) as the features\n",
    "X = compas[['age_cat', 'c_charge_degree', 'race', 'sex', 'priors_count']]\n",
    "Y = compas['two_year_recid']\n",
    "# many ML algorithms take numerical input, so let's convert the categorical variables to numerical\n",
    "X = pd.get_dummies(X, columns = ['age_cat', 'c_charge_degree', 'race', 'sex'], drop_first = True, dtype=int)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throughout this chapter, we will evaluate multiple models in terms of both predictive performance and fairness\n",
    "# For predictive performance: we will report the accuracy, precision, recall, and F1 score\n",
    "# For fairness: we will evaluate conditional demographic disparity and equalized odds\n",
    "# let's create a function so that we don't need to repeat the same code multiple times\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import statsmodels.formula.api as smf\n",
    "def evaluate_model(X_test, y_test, y_pred):\n",
    "    df = X_test.join(pd.DataFrame({'y_true': y_test, 'y_pred': y_pred}))\n",
    "    accuracy = accuracy_score(df['y_true'], df['y_pred'])\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(df['y_true'], df['y_pred'], pos_label = 1, average = 'binary')\n",
    "    # rename columns of df for regression formula\n",
    "    df.rename(columns = {'priors_count': 'priors_count', 'age_cat_Greater than 45': 'age45', 'age_cat_Less than 25': 'age25', 'c_charge_degree_M': 'degree', 'race_Caucasian': 'race', 'sex_Male': 'sex'}, inplace = True)\n",
    "    model_demo = smf.logit(formula = \"y_pred ~ priors_count + age45 + age25 + degree + race + sex\", data = df).fit(disp = 0)\n",
    "    pval_demo = model_demo.pvalues['race']\n",
    "    coef_demo = model_demo.params['race']\n",
    "    model_equalodds = smf.logit(formula = \"y_pred ~ priors_count + age45 + age25 + degree + race + sex + y_true\", data = df).fit(disp = 0)\n",
    "    pval_equalodds = model_equalodds.pvalues['race']\n",
    "    coef_equalodds = model_equalodds.params['race']\n",
    "    # print all metrics\n",
    "    # For disparity metrics, we will report African-American (AA) minus Caucasian (W) values\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1)\n",
    "    print('Conditional Demographic Disparity:', coef_demo, 'with p-value:', pval_demo)\n",
    "    print('Conditional Equalized Odds:', coef_equalodds, 'with p-value:', pval_equalodds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6521464646464646\n",
      "Precision: 0.671003717472119\n",
      "Recall: 0.49115646258503404\n",
      "F1 Score: 0.5671641791044776\n",
      "Conditional Demographic Disparity: -0.6519755776198811 with p-value: 5.975548237556959e-05\n",
      "Conditional Equalized Odds: -0.6477458316017153 with p-value: 7.15534907457676e-05\n"
     ]
    }
   ],
   "source": [
    "# Let's first build a baseline classifier for demonstration\n",
    "# using random forest here, please feel free to try other techniques\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# we will use 70% of the data for training and 30% for testing\n",
    "# setting random_state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# train the random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "evaluate_model(X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Approach: Remove Sensitive Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of pre-processing is to modify the data used for model training to remove the existing bias. Perhaps a seemingly obvious pre-processing approach is to simply drop the sensitive group attribute (```race``` in this case). After all, if the model is \"blind\" to race, it cannot have racial bias, right? Well, let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6515151515151515\n",
      "Precision: 0.65587734241908\n",
      "Recall: 0.5238095238095238\n",
      "F1 Score: 0.5824508320726173\n",
      "Conditional Demographic Disparity: 0.10215799646963158 with p-value: 0.5216770297491757\n",
      "Conditional Equalized Odds: 0.10990842987855276 with p-value: 0.49247397346427646\n"
     ]
    }
   ],
   "source": [
    "# now build another classifier without the race column\n",
    "X_norace_train = X_train.drop(columns = ['race_Caucasian'])\n",
    "X_norace_test = X_test.drop(columns = ['race_Caucasian'])\n",
    "# train the random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_clf.fit(X_norace_train, y_train)\n",
    "# make predictions on the testing data\n",
    "y_pred_norace = rf_clf.predict(X_norace_test)\n",
    "# evaluate the model\n",
    "# note that we still use X_test here because we need the race column for evaluation\n",
    "evaluate_model(X_test, y_test, y_pred_norace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, while removing racial information reduces unfairness to some extent, disparities in terms of outcome and false negative rates remain nontrivial. In general, removing sensitive feature from data has very limited effectiveness. This is because other legitimate features in the data can be correlated with the sensitive feature. Indeed, as shown below, number of prior offenses and age are both correlated with race to some degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priors_count              -0.195713\n",
       "age_cat_Greater than 45    0.182516\n",
       "age_cat_Less than 25      -0.106301\n",
       "c_charge_degree_M          0.102885\n",
       "race_Caucasian             1.000000\n",
       "sex_Male                  -0.069502\n",
       "dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.corrwith(X['race_Caucasian'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Remover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with this issue, we need to systematically remove the correlations between each non-sensitive feature and the sensitive feature. This can be done via the ```CorrelationRemover``` function in the ```fairlearn``` package. Under the hood, it removes correlations by running linear regressions of non-sensitive features on the sensitive feature and obtaining the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priors_count               1.835814e-15\n",
       "age_cat_Greater than 45   -1.833611e-15\n",
       "age_cat_Less than 25       9.469844e-16\n",
       "c_charge_degree_M         -1.044949e-15\n",
       "sex_Male                   9.270897e-16\n",
       "dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fairlearn.preprocessing import CorrelationRemover\n",
    "cr = CorrelationRemover(sensitive_feature_ids=[\"race_Caucasian\"])\n",
    "X_cr = cr.fit_transform(X, Y)\n",
    "# transformation returns a numpy array, let's convert it back to a pandas dataframe\n",
    "X_cr = pd.DataFrame(X_cr, columns = ['priors_count', 'age_cat_Greater than 45', 'age_cat_Less than 25', 'c_charge_degree_M', 'sex_Male']).reset_index(drop = True)\n",
    "# check correlations again - they are very close to 0 now\n",
    "X_cr.corrwith(X['race_Caucasian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6540404040404041\n",
      "Precision: 0.671559633027523\n",
      "Recall: 0.49795918367346936\n",
      "F1 Score: 0.571875\n",
      "Conditional Demographic Disparity: -2.3788645096335537 with p-value: 1.1074149476639748e-34\n",
      "Conditional Equalized Odds: -2.3145107088101136 with p-value: 1.0568928986026908e-32\n"
     ]
    }
   ],
   "source": [
    "# now build another classifier with the transformed data\n",
    "X_cr_train, X_cr_test, y_train, y_test = train_test_split(X_cr, Y, test_size = 0.3, random_state = 42)\n",
    "# train the random forest classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
    "rf_clf.fit(X_cr_train, y_train)\n",
    "# make predictions on the testing data\n",
    "y_pred_cr = rf_clf.predict(X_cr_test)\n",
    "# evaluate the model\n",
    "# note that we still use X_test here because we need the race column for evaluation\n",
    "X_cr_test['race_Caucasian'] = X_test['race_Caucasian']\n",
    "evaluate_model(X_cr_test, y_test, y_pred_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priors_count</th>\n",
       "      <th>age_cat_Greater than 45</th>\n",
       "      <th>age_cat_Less than 25</th>\n",
       "      <th>c_charge_degree_M</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>sex_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5827</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7150</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3694 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      priors_count  age_cat_Greater than 45  age_cat_Less than 25  \\\n",
       "1054             2                        1                     0   \n",
       "731              4                        0                     0   \n",
       "5827             3                        1                     0   \n",
       "44               0                        0                     0   \n",
       "4475             2                        0                     0   \n",
       "...            ...                      ...                   ...   \n",
       "4231             3                        0                     1   \n",
       "5145             1                        1                     0   \n",
       "7102             3                        0                     0   \n",
       "7150            11                        0                     0   \n",
       "1215             3                        0                     0   \n",
       "\n",
       "      c_charge_degree_M  race_Caucasian  sex_Male  \n",
       "1054                  0               0         1  \n",
       "731                   0               0         0  \n",
       "5827                  0               1         0  \n",
       "44                    0               0         1  \n",
       "4475                  0               1         1  \n",
       "...                 ...             ...       ...  \n",
       "4231                  0               0         1  \n",
       "5145                  0               1         1  \n",
       "7102                  0               0         0  \n",
       "7150                  0               0         1  \n",
       "1215                  0               0         1  \n",
       "\n",
       "[3694 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
